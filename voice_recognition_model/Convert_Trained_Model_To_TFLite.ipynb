{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paS3qPtfhNG_"
      },
      "source": [
        "# Converting a trained model to tflite\n",
        "https://www.tensorflow.org/lite/microcontrollers/build_convert#model_conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnDBWJAphNHA"
      },
      "source": [
        "# Convert model to tflite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxfcgogohNHB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cZogqxyhNHC"
      },
      "outputs": [],
      "source": [
        "training_spectrogram = np.load('training_spectrogram (6).npz')\n",
        "validation_spectrogram = np.load('validation_spectrogram (6).npz')\n",
        "test_spectrogram = np.load('test_spectrogram (6).npz')\n",
        "\n",
        "X_train = training_spectrogram['X']\n",
        "X_validate = validation_spectrogram['X']\n",
        "X_test = test_spectrogram['X']\n",
        "\n",
        "complete_train_X = np.concatenate((X_train, X_validate, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqYdko3VhNHC",
        "outputId": "be059c61-d5fd-4033-b079-d131175092e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpc9yibakz'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 99, 43, 1), dtype=tf.float32, name='input_layer_3')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139700925584608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139700925590944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139700925598880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139700925602752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139700925810816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139700925813104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139700925816448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139700925820144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "84112"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('fully_trained_model (5).keras')\n",
        "converter2 = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter2.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "def representative_dataset_gen():\n",
        "    for i in range(0, len(complete_train_X), 100):\n",
        "        # Get sample input data as a numpy array in a method of your choosing.\n",
        "        yield [complete_train_X[i:i+100]]\n",
        "converter2.representative_dataset = representative_dataset_gen\n",
        "# converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "converter2.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "tflite_quant_model = converter2.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_quant_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vK7iw2DhNHD"
      },
      "source": [
        "# To convert to C++\n",
        "This will run a command line too to convert out tflite model into C code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jBLSrz3hNHD"
      },
      "outputs": [],
      "source": [
        "!xxd -i converted_model.tflite > model_data.cc"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
